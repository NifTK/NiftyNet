# -*- coding: utf-8 -*-
"""Partitioner interfaces"""
from __future__ import absolute_import, division, print_function

import math
import os
import random

import pandas
import tensorflow as tf

from niftynet.engine.signal import ALL, INFER, TRAIN, VALID
from niftynet.utilities.util_common import look_up_operations
from niftynet.utilities.util_csv import write_csv

COLUMN_UNIQ_ID = 'subject_id'
COLUMN_PHASE = 'phase'
SUPPORTED_PHASES = {TRAIN, VALID, INFER, ALL}
DEFAULT_SPLIT_FILE_NAME = os.path.join('.', 'dataset_split.csv')


class BaseSetsPartitioner(object):
    """
    This class maintains a ``pandas.dataframe`` of subjects

    Users can query a subset of the dataframe by train/valid/infer partition
    """
    _partition_ids = None
    data_split_file = None

    def __init__(self, file_list=None, data_split_file=None):
        # dataframe of subject images in a shape of subject_id x modality
        self.file_list = file_list
        self.data_split_file = data_split_file or DEFAULT_SPLIT_FILE_NAME

    def initialise(self, new_partition=False, ratios=None):
        if new_partition:
            # generate new data splits and write ``data_split_file``
            uniq_ids = self.file_list[COLUMN_UNIQ_ID]
            _fresh_split = generate_random_split(
                uniq_ids=uniq_ids, ratios=ratios)
            self.data_split_file = write_csv(self.data_split_file,
                                             zip(uniq_ids, _fresh_split))
        self._partition_ids = load_data_split(self.data_split_file)
        tf.logging.info(self)
        return self

    #################################################
    # Interfaces for querying the partitioned sets. #
    #################################################
    def __str__(self):
        return self.to_string()

    def to_string(self):
        """
        Print summary of the partition ids.
        """
        n_subjects = self.number_of_subjects()
        summary_str = '\n\nNumber of subjects {}, '.format(n_subjects)
        if self.file_list is not None:
            summary_str += 'input section names: {}\n'.format(
                list(self.file_list))
        if self._partition_ids is not None and n_subjects > 0:
            n_train = self.number_of_subjects(TRAIN)
            n_valid = self.number_of_subjects(VALID)
            n_infer = self.number_of_subjects(INFER)
            summary_str += \
                'Dataset partitioning:\n' \
                '-- {} {} cases ({:.2f}%),\n' \
                '-- {} {} cases ({:.2f}%),\n' \
                '-- {} {} cases ({:.2f}%).\n'.format(
                    TRAIN, n_train, float(n_train) / float(n_subjects) * 100.0,
                    VALID, n_valid, float(n_valid) / float(n_subjects) * 100.0,
                    INFER, n_infer, float(n_infer) / float(n_subjects) * 100.0)
        else:
            summary_str += '-- using all subjects ' \
                           '(without data partitioning).\n'
        return summary_str

    def number_of_subjects(self, phase=ALL):
        """
        query number of images according to ``phase``.

        :param phase:
        :return:
        """
        if self.file_list is None:
            return 0
        try:
            phase = look_up_operations(phase.lower(), SUPPORTED_PHASES)
        except (ValueError, AttributeError):
            tf.logging.fatal('Unknown phase argument.')
            raise

        if phase == ALL:
            return self.file_list[COLUMN_UNIQ_ID].count()
        if self._partition_ids is None:
            return 0
        selector = self._partition_ids[COLUMN_PHASE] == phase
        selected = self._partition_ids[selector][[COLUMN_UNIQ_ID]]
        subset = pandas.merge(
            self.file_list, selected, on=COLUMN_UNIQ_ID, sort=True)
        return subset.count()[COLUMN_UNIQ_ID]

    def get_file_list(self, phase=ALL, *section_names):
        """
        get image names as a dataframe, by partitioning phase and section names
        set phase to ALL to load all subsets.

        :param phase: the label of the subset generated by self._partition_ids
                    should be one of the SUPPORTED_PHASES
        :param section_names: one or multiple input section names
        :return: a `pandas.dataframe` of file names
        """
        if self.file_list is None:
            tf.logging.warning('File list not initialised.')
            return []
        try:
            phase = look_up_operations(phase.lower(), SUPPORTED_PHASES)
        except (ValueError, AttributeError):
            tf.logging.fatal('Unknown phase argument.')
            raise

        for name in section_names:
            try:
                look_up_operations(name, set(self.file_list))
            except ValueError:
                tf.logging.fatal(
                    'Application requires files under input section [%s],\n'
                    'however the section does not exist in the config.', name)
                raise
        if phase == ALL:
            self.file_list = self.file_list.sort_values(COLUMN_UNIQ_ID)
            return self.file_list[[COLUMN_UNIQ_ID] + list(section_names)] \
                if section_names else self.file_list

        if self._partition_ids is None or self._partition_ids.empty:
            tf.logging.fatal('No partition ids available.')
            raise ValueError

        selector = self._partition_ids[COLUMN_PHASE] == phase
        selected = self._partition_ids[selector][[COLUMN_UNIQ_ID]]
        if selected.empty:
            tf.logging.warning(
                'Empty subset for phase [%s], returning None as file list. '
                'Please adjust splitting fractions.', phase)
            return None
        subset = pandas.merge(
            self.file_list, selected, on=COLUMN_UNIQ_ID, sort=True)
        if subset.empty:
            tf.logging.warning(
                'No subject id matched in between file names and '
                'partition files.\nPlease check the partition files %s,\nor '
                'removing it to generate a new file automatically.',
                self.data_split_file)
        return subset[[COLUMN_UNIQ_ID] + list(section_names)] \
            if section_names else subset

    def has_phase(self, phase):
        """
        Check if the partitioned sets of `phase` is empty.

        :return: True it is not empty.
        """
        if self._partition_ids is None or self._partition_ids.empty:
            return False
        selector = self._partition_ids[COLUMN_PHASE] == phase
        if not selector.any():
            return False
        selected = self._partition_ids[selector][[COLUMN_UNIQ_ID]]
        subset = pandas.merge(
            left=self.file_list, right=selected, on=COLUMN_UNIQ_ID, sort=False)
        return not subset.empty

    @property
    def has_training(self):
        """

        :return: True if the TRAIN subset of images is not empty.
        """
        return self.has_phase(TRAIN)

    @property
    def has_inference(self):
        """

        :return: True if the INFER subset of images is not empty.
        """
        return self.has_phase(INFER)

    @property
    def has_validation(self):
        """

        :return: True if the VALID subset of images is not empty.
        """
        return self.has_phase(VALID)

    @property
    def validation_files(self):
        """

        :return: the list of validation subjects.
        """
        if self.has_validation:
            return self.get_file_list(VALID)
        return self.all_files

    @property
    def train_files(self):
        """

        :return: the list of training subjects.
        """
        if self.has_training:
            return self.get_file_list(TRAIN)
        return self.all_files

    @property
    def inference_files(self):
        """

        :return: the list of inference subjects
            (defaulting to list of all files if no partition definition)
        """
        if self.has_inference:
            return self.get_file_list(INFER)
        return self.all_files

    @property
    def all_files(self):
        """

        :return: list of all subjects
        """
        return self.get_file_list()

    def get_file_lists_by(self, phase=None, action='train'):
        """
        Get file lists by action and phase.

        This function returns file lists for training/validation/inference
        based on the phase or action specified by the user.

        ``phase`` has a higher priority:
        If `phase` specified, the function returns the corresponding
        file list (as a list).

        otherwise, the function checks ``action``:
        it returns train and validation file lists if it's training action,
        otherwise returns inference file list.

        :param action: an action
        :param phase: an element from ``{TRAIN, VALID, INFER, ALL}``
        :return:
        """
        if phase:
            try:
                return [self.get_file_list(phase=phase)]
            except (ValueError, AttributeError):
                tf.logging.warning('phase `parameter` %s ignored', phase)
        # no `phase` specified, now getting the list by `action`
        if action and TRAIN.startswith(action):
            # training action returns both training and validation sets
            return [self.train_files] + [self.validation_files] \
                if self.has_validation else []
        # not training action returns inference set
        return [self.inference_files]

    def reset(self):
        pass


##############################################
# Generating/maintaining ``data_split_file`` #
##############################################
def generate_random_split(uniq_ids, ratios):
    """
    Generate a random split file and write to `data_split_file`.

    :param uniq_ids: a set of unique subject ids
    :param ratios: a tuple of two floats
        `(validation_fraction, inference_set_fraction)`
    :return: a list of phases, each item in uniq_ids assigned a phase
    """
    try:
        valid_fraction, infer_fraction = ratios
        valid_fraction = max(min(1.0, float(valid_fraction)), 0.0)
        infer_fraction = max(min(1.0, float(infer_fraction)), 0.0)
    except (TypeError, ValueError):
        tf.logging.fatal('Unknown format of faction values %s', ratios)
        raise

    if (valid_fraction + infer_fraction) <= 0:
        tf.logging.warning(
            'To split dataset into training/validation, '
            'please make sure '
            '"exclude_fraction_for_validation" parameter is set to '
            'a float in between 0 and 1. Current value: %s.', valid_fraction)
        # raise ValueError

    try:
        n_total = len(uniq_ids.index)
    except (TypeError, AttributeError):
        n_total = len(uniq_ids)
    n_valid = int(math.ceil(n_total * valid_fraction))
    n_infer = int(math.ceil(n_total * infer_fraction))
    n_train = int(n_total - n_infer - n_valid)
    phases = [TRAIN] * n_train + [VALID] * n_valid + [INFER] * n_infer
    phases = phases[:n_total]
    random.shuffle(phases)
    return phases


def load_data_split(data_split_file):
    """
    this function tries to read partition labels from ``data_split_file``.

    :returns: partition ids -- a two column dataframe, first column
        is ``uniq_ids``, the second column is ``phase``.
    """
    data_split_file = os.path.abspath(data_split_file)
    if os.path.isfile(data_split_file):
        tf.logging.warning(
            'Loading from existing partitioning file %s, '
            'ignoring partitioning ratios.', data_split_file)
    else:
        tf.logging.warning('Could not find partitioning ids file %s',
                           data_split_file)

    partition_ids = None
    if os.path.isfile(data_split_file):
        partition_ids = pandas.read_csv(
            data_split_file,
            header=None,
            dtype=(str, str),
            names=[COLUMN_UNIQ_ID, COLUMN_PHASE],
            skipinitialspace=True)

        # validate the partition_ids loaded from file
        if partition_ids is None or partition_ids.empty:
            tf.logging.warning('No partition ids available.')
            if os.path.isfile(data_split_file):
                tf.logging.warning(
                    'Unable to read %s, initialise the'
                    'ImageSetsPartitioner with `new_partition=True`'
                    'to overwrite the file.', data_split_file)
        try:
            phase_strings = partition_ids[COLUMN_PHASE]
            phase_strings = phase_strings.astype(str).str.lower()
            is_valid_phase = phase_strings.isin(SUPPORTED_PHASES)
            assert is_valid_phase.all() and is_valid_phase.count(), \
                "Partition file contains unknown phase id."
            partition_ids[COLUMN_PHASE] = phase_strings
        except (TypeError, AssertionError):
            tf.logging.warning(
                'Please make sure the values of the second column '
                'of data splitting file %s, in the set of phases: %s.\n'
                'Remove %s to generate random data partition file.',
                data_split_file, SUPPORTED_PHASES, data_split_file)
            raise ValueError
    return partition_ids
