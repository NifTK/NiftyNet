# -*- coding: utf-8 -*-
"""Create input data reader"""

from __future__ import absolute_import, division, print_function

import argparse
from copy import deepcopy

import tensorflow as tf
from six import string_types

from niftynet.utilities.user_parameters_helper import make_input_tuple
from niftynet.utilities.util_common import ParserNamespace, look_up_operations
from niftynet.io.memory_image_source import MEMORY_INPUT_CALLBACK_PARAM

SUPPORTED_DATA_SPEC = {
    'csv_file', 'path_to_search', 'filename_contains', 'filename_not_contains',
    'filename_removefromid', 'interp_order', 'loader', 'pixdim', 'axcodes',
    'spatial_window_size', MEMORY_INPUT_CALLBACK_PARAM
}


class ImageReader:
    """
    Module to validate user input and create image source.
    """

    def __init__(self, names=None):
        """
        :param names: the list of section names (in
            task_param) describing the modalities.
        """
        self._names = None
        if names:
            self.names = names

    @property
    def names(self):
        """

        :return: the keys of ``self.input_sources`` dictionary
        """
        return self._names

    @names.setter
    def names(self, fields_tuple):
        """
        output_fields is a sequence of output names
        each name might correspond to a list of multiple input sources
        this should be specified in CUSTOM section in the config
        """
        self._names = make_input_tuple(fields_tuple, string_types)

    # pylint: disable=too-many-arguments
    def initialise(self,
                   data_param,
                   task_param=None,
                   file_list=None,
                   phase_indices=None,
                   from_files=True):
        """
        ``task_param`` specifies how to combine user input modalities.
        e.g., for multimodal segmentation 'image' corresponds to multiple
        modality sections, 'label' corresponds to one modality section

        This function converts elements of ``file_list`` into
        dictionaries of image objects, and save them to ``self._output_list``.
        e.g.::

             data_param = {'T1': {'path_to_search': 'path/to/t1'}
                           'T2': {'path_to_search': 'path/to/t2'}}

        loads pairs of T1 and T1 images (grouped by matching the filename).
        The reader's output is in the form of
        ``{'T1': np.array, 'T2': np.array}``.
        If the (optional) ``task_param`` is specified::

             task_param = {'image': ('T1', 'T2')}

        the reader loads pairs of T1 and T2 and returns the concatenated
        image (both modalities should have the same spatial dimensions).
        The reader's output is in the form of ``{'image': np.array}``.


        :param data_param: dictionary of input sections
        :param task_param: dictionary of grouping
        :param file_list: a dataframe generated by ImagePartitioner
            for cross validation, so
            that the reader only loads files in training/inference phases.
        :return: the initialised reader instance
        """

        data_param = param_to_dict(data_param)

        if not task_param:
            task_param = {mod: (mod, ) for mod in list(data_param)}
        try:
            if not isinstance(task_param, dict):
                task_param = vars(task_param)
        except ValueError:
            tf.logging.fatal(
                "To concatenate multiple input data arrays,\n"
                "task_param should be a dictionary in the form:\n"
                "{'new_modality_name': ['modality_1', 'modality_2',...]}.")
            raise
        if not self.names:
            # defaulting to load all sections defined in the task_param
            self.names = list(task_param)

        self.names, input_sources = \
            self._get_section_input_sources(task_param, self.names)

        if from_files:
            from niftynet.io.file_image_source import FileImageSource
            source_inst = FileImageSource()
            source_inst.initialise(
                data_param, input_sources, file_list=file_list)
        else:
            from niftynet.io.memory_image_source import MemoryImageSource
            source_inst = MemoryImageSource()
            source_inst.initialise(
                data_param, input_sources, phase_indices=phase_indices)
        return source_inst

    @staticmethod
    def _get_section_input_sources(task_param, section_names):
        """
        Filters a list of section names against a task_param
        struct eliminating any invalid section names. Throws an
        exception if no valid entries are found in the list.

        :param task_param: task_param dictionary of application
        specific settings.
        :param section_names: list of image specification sections.
        :return: the filtered list of section names and the dictionary
        of corresponding modalities.
        """

        if not isinstance(task_param, dict):
            task_param = vars(task_param)

        valid_names = [
            name for name in section_names if task_param.get(name, None)
        ]
        if not valid_names:
            tf.logging.fatal(
                "Reader requires task input keywords %s, but "
                "not exist in the config file.\n"
                "Available task keywords: %s", section_names, list(task_param))
            raise ValueError

        modalities = {name: task_param.get(name) for name in valid_names}

        return valid_names, modalities


def param_to_dict(input_data_param):
    """
    Validate the user input ``input_data_param``
    raise an error if it's invalid.

    :param input_data_param:
    :return: input data specifications as a nested dictionary
    """
    error_msg = 'Unknown ``data_param`` type. ' \
                'It should be a nested dictionary: ' \
                '{"modality_name": {"input_property": value}} ' \
                'or a dictionary of: {"modality_name": ' \
                'niftynet.utilities.util_common.ParserNamespace}'
    data_param = deepcopy(input_data_param)
    if isinstance(data_param, (ParserNamespace, argparse.Namespace)):
        data_param = vars(data_param)
    if not isinstance(data_param, dict):
        raise ValueError(error_msg)
    for mod in data_param:
        mod_param = data_param[mod]
        if isinstance(mod_param, (ParserNamespace, argparse.Namespace)):
            dict_param = vars(mod_param)
        elif isinstance(mod_param, dict):
            dict_param = mod_param
        else:
            raise ValueError(error_msg)
        for data_key in dict_param:
            look_up_operations(data_key, SUPPORTED_DATA_SPEC)
        data_param[mod] = dict_param
    return data_param
